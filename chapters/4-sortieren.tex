% Copyright \copyright\ 2010  Volodymyr Piven und Alexander Peltzer.
% Es wird die Erlaubnis gegeben, dieses Dokument unter den Bedingungen der von der Free
% Software Foundation veröffentlichen  GNU Free
% Documentation License (Version 1.2 oder neuer) zu kopieren, verteilen und/oder
% zu verändern. Eine Kopie dieser Lizenz ist unter
% http://www.gnu.org/copyleft/fdl.txt erhältlich.
%
% Copyright der Aktualisierung und Überarbeitung \copyright\ 2013  Simon Kalt, Jan-Peter Hohloch, Tobias Fabritz
% Es wird die Erlaubnis gegeben, dieses Dokument unter den Bedingungen der von der Free
% Software Foundation veröffentlichen  GNU Free
% Documentation License (Version 1.2 oder neuer) zu kopieren, verteilen und/oder
% zu verändern. Eine Kopie dieser Lizenz ist unter
% http://www.gnu.org/copyleft/fdl.txt erhältlich.
%
% Zusätzlich muss jede Kopie/Aktualisierung wieder über die Seite
% der Fachschaft Informatik der Uni Tübingen
% den Studenten zur Verfügung gestellt werden
% http://www.fsi.uni-tuebingen.de/

\chapter{Sortieren}
    $A: 11,3,4,5,4,12 \quad \rightarrow \quad B:3,4,4,5,11,12$\\
    \begin{tabbing}
        Verfahren: \= 1.Min\=imumsuchev + Austausch mit 1. Element usw. \\
		\> \> $T(n) = \LO(n) + T(n-1) \underset{\text{kleiner Gauss}}{=} \LO(n^{2})$\\
        \> 2.Insertionsort: Füge immer an richtige Stelle ein. Mache Platz\\
		\> \>  $T(n) = T(n-1) + O(n) = \LO(n^{2})$\\
        \> 3.Bubble Sort: In $i$-ter Iteration sind die ersten $i-1$ Stellen \\
		\> schon sortiert. Tausche jeweils 'groß' gegen 'klein' aus $S[i,n]$\\
		\>\>$T(n)= O(n) + T(n-1) = \LO(n^{2})$\\
        \> 4.Quicksort, Heapsort, MergeSort, BucketSort
    \end{tabbing}
        

    \section{Quicksort(Divide and Conquer)}
        Eingabe $S$ \ \ $a_1, \ldots , a_n$
        \begin{enumerate}
           \item Wähle Pivotelement $a_1$ \\
           Teile $S \verb=\= \{ a_1 \}$ auf in $A= \{a_i \mid a_i \leq a_1 \text{ für } i \geq 2 \}$, 
           	$B = \{a_i \mid a_i > a_1 \text{ für } i \geq 2 \}$ \\
           Speichere A in $S[1], \ldots, S[i]$ $a_1$ in $S[j+1]$, $B$ in $ S[j+2], \ldots S[n]$ 
           \item Sortiere A und B rekursiv. 
        \end{enumerate}

        Analyse: Schlechtester Fall: wenn $a_1$ minimal $(A = \varnothing)$ oder $a_1$ maximal $(B = \varnothing)$. \\
        $\Ra \#$ Vergleiche: $(n-1)+(n-2)+(n-3) + \ldots + 1 = \frac{n(n-1)}{2} = \LO(n^2)$ \\
        Mittlere Analyse: Modelliere Elemente paarweise verschieden, jede der $n!$ möglichen Permutationen der Eingabe ist gleich wahrscheinlich\\
        oBdA: $S = \{1,2,\ldots, n \} \\ S[1]$ mit Wahrscheinlichkeit $\frac{1}{n}$ für $k=1,2,\ldots, n$ \\
        Teilprobleme der Größe $k-1$ bzw. $n - k$ erfüllen wieder die W' annahmen. \\\\
        Sei $\overline{QS}(n)$ die mittlere Anzahl von Vergleichen an Feld der Grö\ss e $n$. Es gilt:
        $$\overline{QS} (0) = \overline{QS}(1) = 0$$
        sowie für $n \geq 2$: 
        \begin{align*}
            \overline{QS}(n) &= n + E(\overline{QS}(A)+ \overline{QS}(B))  \\
            &= n + \frac{1}{n} \cdot \sum \limits_{k-1}^n \overline{QS} (k-1) + \overline{QS}(n-k) \\
            &= n + \frac{2}{n} \cdot \sum \limits_{k=1}^{n-1} \overline{QS} (k)
        \end{align*} 
        Es lassen sich nun die Formeln
        \begin{align*}
            n \cdot \overline{QS}(n) &= n^2 + 2 \sum \limits_{k-1}^{n-1} \left( \overline{QS}(k) \right) \tag{i} \\
            (n+1) \cdot \overline{QS} (n+1) &= (n+1)^2 + 2 \cdot \sum \limits_{k-1}^n \left( \overline{QS}(k) \right) \tag{ii}
        \end{align*}
        bilden und damit gilt
        \begin{align*}
            \text{(ii) - (i)} &= (n+1) \cdot \overline{QS}(n+1) - n \cdot \overline{QS}(n) = (n+1)^2 -n^2 +2 \cdot \overline{QS}(n) \\
            (n+1) \cdot \overline{QS} (n+1) &= 2n+1~+~(n+2)\cdot \overline{QS} (n) \\
            \overline{QS} (n+1) & \overset{\frac{2n+1}{n+1}\le 2}{\le} 2 + \frac{n+2}{n+1} \cdot \overline{QS} (n) \\
            &= 2 + \frac{n+2}{n+1}\cdot \left( 2+ \frac{n+1}{n} \cdot \overline{QS} (n-1) \right) \\
            &= 2 + (n+2) \cdot \left( \frac{2}{n+1} + \frac{2}{n} + \frac{2}{n-1} + \ldots + \frac{2}{2} + \frac{2}{1} \right) \\
            \overline{QS} (n) &= 2 + 2 \cdot (n+2) 
            	\cdot \underbrace{\left( \frac{1}{n} + \frac{1}{n-1} + \frac{1}{n-2} + \ldots + 1 \right)}_{\text{harmonische Reihe}} \\
            &< 2 + 2 \cdot (n+2) \cdot \left( \ln n + 1 \right) \\
            &\Rightarrow \LO(n \cdot \log(n))
        \end{align*}


    \section{Heap Sort}
        Ähnlich zu \q{Sortieren durch Min-Suche}. \\
        \begin{definition}
            Heap ist Binärer Baum:\\
            Er ist entweder leer, oder hat Wurzelknoten mit linkem und rechtem Teilbaum.
        \end{definition}
        
        Dabei gilt für Baum $T$ und Knoten $v$ in $T$: 

        \begin{align*}
            \text{Tiefe}(v) &= \begin{cases}
                                0 &, \text{ falls $v$ Wurzel von $T$} \\
                                \text{Tiefe}(\text{Parent}($v$)) + 1 &, \text{ sonst}
                            \end{cases} \\
            \text{Höhe}(v) &= \begin{cases}
                                0 &, \text{ falls $v$ Blatt} \\
                                \text{max}(\{\text{Höhe($u$)} \mid \text{$u$ Kind von $v$} \}) + 1 &, \text{ sonst}
                            \end{cases} 
        \end{align*}

    %    momentan kein Bsp
    %    Beispiel Höhe$(v) = 1$ \\
    %    Beispiel Höhe$(u) = 3$ \\
        Allgemein gilt für Baum T:
        % Tiefe$(T) = max \{ \text{Tiefe } (v) \mid v \in T \}$ \\
        % Höhe$(T) = \text{Höhe } \{ \text{ Wurzel }(T) \} = \text{max(Höhe(v) für } v \in T)$ \\

        \begin{align*}
            \text{Tiefe}(T) &= \text{max}(\{\text{Tiefe}(v) \mid v \in T\}) \\ 
            \text{Höhe}(T)  &= \text{Höhe}(\text{Wurzel}(T)) = \text{max}(\{\text{Höhe}(v) \mid v \in T\}) 
        \end{align*}


        Heap wird durch binären Baum dargestellt, wobei jedes Element aus $S$ einem Knoten aus $h$ zugeordnet wird. \\
        Heapeigenschaft: für Knoten mit $u,v$ mit $\text{parent}(v) = u$ gilt $S [u] \leq S [v]$ \\
        
        Beobachtung: \\ 
        Beim Heap stet das Minimum in der Wurzel. Sortieren durch Min-Suche. \\
        1. Suche: Min $\ra$ Wurzel $\LO(1)$ \\
        2. Lösche Min aus Suchmenge und repariere Heap. \\

        Ablauf: \\
        \begin{itemize}
            \item Nimm Blatt und füge es zu Wurzel hinzu
            \item Lass es \q{nach unten sinken} (vertausche mit kleinstem Kind)
            \item \# Iterationen $\leq$ Höhe$(T)$ 
        \end{itemize}
        Höhe sollte also klein sein\\
        $\Rightarrow$ Ausgewogene Bäume:
        \begin{itemize}
       	\item Alle Blätter haben Tiefe $k$ oder $k+1$ 
        	\item Blätter auf Tiefe $k+1$ stehen ganz links. 
        \end{itemize}
        \q{Kanonische Form}: Es gilt auf Tiefe $1,2, \ldots, k$ liegen $2^1, \ldots, 2^k$ Knoten.

        \begin{figure}[htp]
            \input{diagramme/unbalanced_heap}
            \caption{Unausgewogener Heap Baum}
            \label{diag3:unbalanced-heap-tree}
        \end{figure}

        In Abb. \ref{diag3:unbalanced-heap-tree} ist ein Beispiel-Heap als Baum dargestellt.
        Dieser ist noch nicht ausgewogen. Eine mögliche ausgewogene Variante für diesen Baum
        ist in Abb. \ref{diag3.5:balanced-heap-tree} dargestellt.

        
        \begin{figure}[htp]
            \input{diagramme/Diagramm3.5-Heap-Balanced}
            \caption{Ausgewogener Heap Baum mit Nummerierung der Elemente}
            \label{diag3.5:balanced-heap-tree}
        \end{figure}

        Es gilt für Knoten mit Nummer $i$: $parent(i)$ hat die Nummer
        $\left\lfloor \frac{i}{2} \right\rfloor$, Kinder haben $2i$ und $2i+1$.
        Der Heap wird nur konzeptuell als Baum dargestellt. Implementiert
        wird dieser als Array mit einer Indizierung ab 1. Der Heap wird wie
        in Algorithmus \ref{alg:init-heap} beschrieben initialisiert.

        \begin{algorithm}[htp]
            \caption{Initialisierung des Heaps $h$}
            \label{alg:init-heap}
            \begin{algorithmic}
                \ForAll{$a \in S$}
                    \State \Call{insert}{$a$, $h$}
                \EndFor

                \Function{insert}{$a$, $h$}
                    \State $n \gets $ size(h) $ + 1$
                    \State $A(n) \gets a$
                    \State $i \gets n$
                    \State $j \gets n$
                    \State $\var{done} \gets (i = 1)$
                    \While{$\lnot \var{done}$}
                        \State $j \gets \left\lfloor\frac{j}{2}\right\rfloor$
                        \If{$A(j) > A(i)$}
                            \State swap($A(i), A(j)$)
                            \State $i \gets j$
                        \Else
                            \State $\var{done} \gets \True$
                        \EndIf
                    \EndWhile
                \EndFunction
            \end{algorithmic}
        \end{algorithm}

        \subsection{Laufzeit}
        Initialisierung: $\LO(n \cdot \text{Höhe}(H))$ \\
        eigentliche Sortierung: $\LO(n \cdot \text{Höhe}(H)$ \\
        Höhe$(H)$ ist $\LO(\log n)$, da Baum ausgewogen ist. \\
        \begin{satz}    
            Lemma: Hat ein ausgewogener Baum die Höhe $k$, so hat er mindestens $2^k$ Knoten.
        \end{satz}
        \begin{proof}
            Der kleinste Baum der Höhe $k$ hat nur ein Blatt mit Abstand $k$ zur Wurzel. Auf Stufe $i$ gibt es $2^i$ Knoten für $0 \leq i \leq k-1$ plus einen Knoten auf Stufe $k$. Damit ist die Anzahl der Knoten
            $$
                \sum^{k-1}_{i=0}{2^i} + 1 = 2^k
            $$
        \end{proof}        
        Damit ist $n \geq 2^k$ und $\log n \geq k = \text{Höhe}(H)$
        \begin{satz}
            HeapSort läuft in Zeit $\LO(n \log n)$, auch im Worst-Case. \\
        \end{satz}
        Beachte $\overline{QS} \leq 2 \cdot n \log n$ \\
        Frage: Wie ist HeapSort-Konstante? \\
        (Diese Frage wurde von Prof. Kaufmann offen gelassen ;) )

    \section{MergeSort}
        Prinzip: mische 2 sortierte Folgen zusammen zu einer. \\
        \begin{math}
	        \left.
	        	\begin{array}{c}
	        		(1, 2, 4, 7)\\
	        		(5,6,8) 
	        	\end{array}
	        \right\rbrace \rightarrow (1,2,4,5,6,7,8) \\
        \end{math}
        Es werden immer die aktuell minimalen Elemente verglichen $(\LO(1))$ und dann das kleinste ausgeschrieben. \\
        \underline{Idee:} \\
        Starte mit Teilfolgen der Länge 1. ($n$ Teilfolgen) \\
        Mache daraus Teilfolgen der Länge 2 $(\frac{n}{2}$ Teilfolgen) \\
        usw. bis aus 2 Teilfolgen eine entsteht. \\
        \underline{Laufzeit:}\\
        Teilfolgen haben nach der $i$-ten Iteration die Länge $\leq 2^i$. Ist $2^i \geq n \Ra i \geq \log n$ Iterationen\\
        Pro Iteration mache $\LO(n)$ Vergleiche. $\Ra$ Insgesamt $\LO(n \log n)$ Vergleiche.\\
        \emph{Allgemeiner:} \\
        \q{m-Wege-Mischen}: $\LO(\log_m n)$ Iterationen. Dabei fügt man immer m Folgen zusammen.
    


    \section{Bucket Sort}
        (Sortieren durch Fachverteilung)\\
        \emph{Gegeben:} Wörter über Alphabet $\Sigma$. Sortiere lexikographisch. Als Ordnung gilt
        \begin{align*}
            a < B \\
            a < aa < aba \\ 
            \text{mit } \abs{\Sigma}=m
        \end{align*}
        \begin{enumerate}
            \item Fall: Alle Wörter haben Länge 1. Stelle $m$ Fächer bereit (für $a,b,c, \ldots, z$). Diese Fächer müssen sortiert sein.
            Wirf jedes Wort in entspr. Fach. Konkateniere die Inhalte der Fächer.\\
            $\Rightarrow$ Laufzeit: $\LO(n) + \LO(m)$\\
            Implemetiere einzelne Fächer als lin. Listen.\\
            
            \item Fall: Alle Wörter haben Länge $k$. Sei Wort $a^{i} = a_{1}^{i} a_{2}^{i} \cdots a_{k}^{i}$ 
            das $i$-te Wort, $1 \leq i \leq n$\\
            \emph{Idee:} Sortiere zuerst nach dem letzten Zeichen, dann dem vorletzten, usw. Damit sind Elemente, die zum 
            Schluss ins gleiche Fächer fallen, richtig geordnet.\\
            \emph{Laufzeit:} $\LO((n+m)k)$\\
            \emph{Problem:} Wollen leere Listen überspringen beim Aufsammeln der Listen. Also Ziel: statt 
            $\LO((n+m)k)$ besser $\LO(n\cdot k + m)$.\\
            Erzeugen Paare $\left( j, a^{i}_{j} \right),~1 \leq i \leq n,~1 \leq j \leq k$.\\
            Sortiere nach 2. Komp., dann nach der ersten, dann liegen im $j$-ten Fach die Buchstaben sortiert, die an der 
            $j$-ten Stelle vorkommen.\\
            $\Rightarrow$ leere Fächer werden übersprungen.\\
            $\Rightarrow$ Laufzeit: $\LO(n \cdot k + m)$\\
            
            \item Fall: (Der allgemeine Fall) \\
            Wort $a^{i}$ habe Länge $l_{i}$ Sei
            \begin{align*}
                L = \sum \limits_{i=1}^{n} l_{i}\\
                R_{max} = \max \lbrace l_{i} \rbrace\\
            \end{align*}
            \emph{Idee:} Sortiere Wörter der Länge nach und beziehen zuerst die langen Wörter ein. \\
            \emph{Algorithmus:}             
            \begin{enumerate}
                \item Erzeuge Paare $\left( l_{i}, \text{ Verweis auf } a^{i} \right)$\\
                \item Sortiere Paare durch Bucketsort nach 1.Komp\\
                \item Erzeuge $L$ Paare $\left( j, a_{j}^{i} \right), 1 \leq i \leq n, 1 \leq j \leq l_{i}$ 
                    und sortiere zuerst nach 2. Komp., dann nach 1. Komp. Diese liefert lineare Listen $\text{Nichtleer}(j)$, $1 \leq j \leq r_{max}$\\
                \item Sortiere nun $a^{i}$s durch Bucketsort wie oben unter Berücksichtigung von $L(k)$
            \end{enumerate}
        \end{enumerate}

        
        

        \begin{satz}
            Bucketsort sortiert $n$ Wörter der Gesamtlänge $L$ über Alphabet $\sum,~\btl \sum \btr = m$ in Zeit $\LO(m + L)$
        \end{satz}
        Beispiel für den 2. Fall:        
        \begin{bsp}
            124, 223, 324, 321, 123
            \begin{table}[!htbp]
                \centering
                \begin{tabular}{c|c|c|c|c}
                    Fächer & 1 & 2 & 3 & 4\\
                    \hline
                    1.Iter. & 321 & & 223 & 124\\
                    & & & 123 &\\
                    \hline
                    2.Iter. & & 321 & &\\
                    & & 223 & &\\
                    & & 123 & &\\
                    & & 124 & &\\
                    & & 224 & &\\
                    \hline
                    3.Iter. & 123 & 223 & 321 & \\
                    & 124 & 224 &&
                \end{tabular}
            \end{table}
        \end{bsp}

% 2013 nicht behandelt
%    \section{Hybridsort}
%        Jetzt reelle Zahlen aus $\rbrack 0,1 \rbrack$:  \\
%        Hybridsort: Sei $k = c \cdot n$ mit $c \in \R$ fest. \\
%        \begin{enumerate}[1.)]
%            \item Wirf $a_i$ in Fach $\lceil k \cdot a_i \rceil$ für $1 \leq c \leq n$ 
%            \item Wende HeapSort auf jedes Fach an und konkateniere die Fächer.
%        \end{enumerate}
%        Laufzeit:\\
%        Worst case: $\LO(n \log n)$ \\
%        average case: Sind $a_i$ unabhängig und gleichverteilt , so hat Hybrid Sort Laufzeit $\LO(n)$. \\


    \section{Auswahlproblem} 
        Finde den Median (mittleres Element) \\
        \emph{formal}:\\ Gegeben Menge $S$ von $n$ Zahlen und Zahl $i$, $1 \leq i \leq n$. Finde $x$ mit $\btl \{ y | y> x \} \btr = i - 1$
       
        \begin{enumerate}[1.]
            \item Idee: Sortiere und ziehe dann das $i$-te Element $\Ra \LO(n \log n)$


               \item Idee: Wie Quicksort \\
                Random. Partiion $(A, q,r)$ zerlegt Array $A$ zwischen Indizes $p$ und $r$ an zufälliges Element $q$ in zwei Mengen 
               $A \lbrack p, q-1 \rbrack$ und $A \lbrack q+1, r \rbrack$ 
        \end{enumerate}
            \underline{Random-Select} $(A,p,r,i)$ \\
\begin{algorithm}
\caption{RandomSelect}
\label{alg:randomSelect}
\begin{algorithmic}[1]
\Function{RandomPartition}{A,p,r}
\State A zerteilt in p und r an zufälligen q in Mengen A[p,q-1], A[q+1,r]
\EndFunction
\Function{RandomSelect}{$A,p,r,i$}
	\If{$p = r$}
		\Return $A[p]$
	\EndIf
	\State $q \gets$ \Call{Random Partition}{A,p,r} ($\in \LO(r-p))$
	\State $k \gets q-p+1$
	\If{$i = k$}
		$A[q]$
	\Else
		\If{$i < k$}
		\State\Return\Call{RandomSelect}{$A,p,q-1,i$}
	\Else\ 
		\State\Return\Call{RandomSelect}{A,q+1,r,i}
	\EndIf
	\EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}
           worst case: $\LO(n^2)$, ideal case: $n + \frac{n}{2} + \frac{n}{4} + \ldots + 2 + 1 = \LO(2n) \in \LO(n)$ \\
            average case: Sei $T(n)$ Zufallsvar. für die Laufzeit von Random Selection. \\
            Random Partition zerlegt die Menge der Größe $n$ mit Wahrscheinlichkeit $\frac{1}{n}$ in Teilmengen der Größen $k$ und $n-k$. \\
            Also definiere für $k=1,2, \ldots, n$ \\
           $x_k = \begin{cases} 1 & \text{ falls } A \lbrack p,q \rbrack  k \text{ Elemente hat} \\
            0 & \text{ sonst}
            \end{cases} \Ra E(X_k) = \frac{1}{n}$
            \underline{Beobachtung}: 
            \begin{itemize}
                \item $T(n)$ ist monoton.
                \item Laufzeit ist größer, falls $i$ in größerer Teilmenge.
            \end{itemize}
            $\Ra $
            \begin{eqnarray*}
                T(n) & \leq &  \sum \limits_{k=1}^n X_k \cdot (T(\max(k-1, n-1))+ \LO(n)) \\
                &=& \sum \limits_{k=1}^n X_k \cdot T(\max(k-1, n-k)) + \LO(n) 
            \end{eqnarray*}
            und damit : \\
            \begin{eqnarray*}
                E(T(n)) &=& E( \sum \limits_{k=1}^n X_k \cdot T(\max (k-1, n-k)) + \LO(n)) \\
                &=& E(\sum \limits_{k=1}^n X_k \cdot T(\max(k-1, n-k)) + \LO(n) \\
                &=& \sum E(X_k) \cdot E(T_{\max} (k-1, n-k)) + \LO(n) \\
                &=& \sum \limits_{k=1}^n \frac{1}{n} \cdot E(T_{\max} (k-1, n-k)) + \LO(n) \\
                &\leq& \frac{2}{n} \sum \limits_{k= \lfloor \frac{n}{2} \rfloor}^{n-1} E(T(k)) + \LO(n)
            \end{eqnarray*}
            Da $X_k$ und $T_{\max}$ unabhängig sind.
        
        \underline{Behauptung}: $E(T(n)) \leq c \cdot n$ für konstantes $c$. \\
        $T(n) = \LO(1)$ falls $n$ konstant $\surd$. 
        Induktion: \\
          
        \begin{eqnarray*}
            E(T(n)) &\leq& \frac{2}{n} \sum \limits_{k=\lfloor \frac{n}{2} \rfloor}^n c \cdot k + a \cdot n \text{  (a ist geeignete Konstante.) } \\
            &=& \frac{2c}{n} ( \sum \limits_{k=1}^{n-1} k - \sum \limits_{k=1}^{\lfloor \frac{n}{2} \rfloor -1} k) + a \cdot n \\
            &\leq& \frac{2c}{n} \cdot (\frac{n^2}{2} - \frac{(\frac{n}{2})^2}{2} ) + a \cdot n \\
            &\leq & \frac{2n}{n} \cdot ( \frac{3}{8} n^2) + a \cdot n \\
            &=& \frac{3}{4} \cdot c \cdot n + a \cdot n \leq c \cdot n \text{ für } a \leq \frac{c}{4}
        \end{eqnarray*}
          
        Bessere Version:
        \begin{enumerate}
            \item Teile $n$ Elemente in $\frac{n}{5}$ Gruppen der Größe $5$, sortiere sie und bestimme Median jeder Gruppe.
            \item Suche rekursiv den Median $x$ der Mediane.
            \item Teile Menge $S$ bezüglich $x$ in 2 Mengen $S_1, S_2$. Sei $\btl S_1 \cup x \btr = k$ und $\btl S_2 \btr = n-k$
            \item 
            \begin{algorithmic}
				\begin{algorithm}
				\If{i = k}\State \Return $x$
				\Else 
					\If{$i < k$}
				\State \Call{Auswahl}{$S_1, i$}
				\Else
				\State \Call{Auswahl}{$S_2, i-k$}
				\EndIf
				\EndIf
				\end{algorithm}
            \end{algorithmic}
        \end{enumerate}
        Wieso Mediane? \\
        $\frac{1}{2} \cdot \frac{n}{5}$ der Mediane sind größer als $x$. Die Gruppen dieser Mediane liefern jeweils $3$ Elemente, die größer sind als $x$; also sind 
        mindestens $\frac{3}{10} n $ Elemente größer als $x$ und genauso $\frac{3}{10}n$ kleiner. \\
        $\Ra \btl S_1 \btr, \btl S_2 \btr \leq \frac{6n}{10}$ \\
        Um $\frac{6}{10}$ schrumpft die Menge rekursiv mindestens. \\
        \emph{Laufzeit:} \\
        $T(n) = \begin{cases} 
        \LO(1) & \text{ falls n konstant ist} \\
        T(\frac{n}{5}) + T(\frac{5n}{10}) + c \cdot n & \text{ sonst}
        \end{cases}$ \\
        Behauptung: $T(n)  = c \cdot n$ für $c$ konstant, also $T(n) = \LO(n)$ \\    
        Induktion: 
        \begin{eqnarray*}
            T(n) & \leq & c \cdot \frac{n}{5} + c \cdot \frac{7n}{10} + a \cdot n \\
            &=& \frac{9}{10} c \cdot n + a \cdot n \leq c \cdot n \text { für } a \leq \frac{c}{10}
        \end{eqnarray*} $\surd$

        \begin{satz}
            In zeit $\LO(n)$ können wir das $i$-te größte element aus einer ungeordneten Menge bestimmen.
        \end{satz}
\subsection{Ist $n \log n$ optimale Lösung?}
Idee : Hat Problem $N$ verschiedene Lösungen und kann ein Algorithmus
pro Schritt höchstens die Hälfte der Lösungen ausschließen ist die Laufzeit 
$\Omega(\log N)$ im schlechtesten Fall.\\
Sortieren: Vergleichsbasiert: Nur Paare von Elementen vergleichen
Resultat: $\leq$ oder $>$.\\
Algorithmus wird dargestellt als Entscheidungsbaum.\\
Knoten $s_i:s_j$ steht für Vergleich zwischen $s_i$ und $s_j$.\\
Kante zum linken Kind steht für Ergebnis $S_i \leq s_j$,\\
Kante zum rechten Kind steht für Ergebnis $s_i > s_j$\\
Beispiel\\
Pfad von Wurzel zu Blatt entspricht Folge von Vergleichen,\\
die zu einem dazu passenden Ergebnis fuhren.\\
\subsubsection{Entscheidungsbaum}
Entscheidungsbaum $T$ löst Sortierproblem für $n$ Elemente, falls es 
Markierungen der Blätter mit Permutationen gibt, so dass für jede Eingabe $s_1,\ldots,s_n \in U$ gilt:
Ist das erreichte Blatt mi $\pi$ markiert, so gilt: $s_\pi(1) \geq \ldots s_\pi(n$)
vergleichbasierte Sortieralgorithmen $\equiv$  Entscheidungsbäume $\to$ Entscheidungsalgorithmen\\
Für Entscheidungsbaum $T$ und Permutation $\pi$ von $\{1,2,\ldots n\}$ sei $I^T_pi$ die Tiefe des Blatts Für EIngabe $s_1,\ldots,s_n$ mit $s_{\pi(1)} \leq \ldots \leq s_{\pi(n)}$\\
Definiere $S(n) :\!= min_T max_\pi I^T_\pi\\
S(n)$ ist die minimale worst-case Komplexität des Sortierproblems.\\
Das es $n!$ Permutationen für $\{ 1,2,\ldots,n \}$ gibt, muss ein Entscheidungsbaum mindestens $n!$ Blätter haben.\\
\begin{satz}
$S(n)  = \lceil \log n! \rceil$.\\
also: Jeder Entscheidungsbaumalgorithmus für Sortieren braucht im worst case mindestens $\lceil \log n! \rceil$ Vergleiche.
\end{satz}
\begin{proof}
Binäre Bäume der Tiefe $k$ haben $\leq 2^k$ Blätter. Ist $S(n) \leq \lceil \log n! \rceil - 1$, so gibt es T mit Tiefe $\leq \lceil \log n! \rceil -1 $ für alle Blätter\\
$\Rightarrow T$ hat $\leq 2^{\lceil \log n! \rceil -1} < 2^{\log n!} = n!$ Blätter
$\Lightning$
\end{proof}
$\to$ Stirlingapproximation:\\
$\log n! = (n + 1/2)\log n -n/\ln 2 + O(1) = n \log n -1.44 n + O(\log n)$
\subsection{Elementeindeutigkeitsproblem}
Gegeben: $s_1,\ldots s_n \in U$, entscheide, ob alle verschieden sin, also $s_1 \ne s_j$ für alle $i \ne j$.
Im Entscheidungsbaum $T$ für $E$-Eindeutigkeit haben Blätter Markierungen 'Ja' oder 'Nein'.\\
An Folge $s_1 \ldots, s_n$ wird 'ja' Blatt erreicht $\Leftrightarrow$ $s_i \ne s_j$ für alle $i \ne j$.\\
Behauptung: $T$ hat mindestens $n!$ Blätter\\
Beweisidee:
\begin{enumerate}[1.]
\item Sei $v(\pi)$ das bei der Folge $\pi^{-1}(1),\ldots,\pi^{-1}(n)$ für Permutationen $\pi$ von $\{1,\ldots,n \}$ erreichte Blatt. Dann wird Blatt $v(\pi)$ für jede Folge $s_1,\ldots,s_n$ mit $s_{\pi(1)} < s_{\pi(2)} < \ldots < s_{\pi(n)}$ erreicht.
\item Für 2 Permutationen $\pi \ne p$ gilt $v(\pi) \ne v(p)$, also enden Berechnungen jeweils in verschiedenen Blättern.
\end{enumerate}
Verschiedene Permutationen enden in verschieden Blättern.\\
$\Rightarrow\ T$ hat mindestens $n!$ Blätter.
\begin{satz}
Jeder Entscheidungsbaumalgorithmus für Elementeindeutigkeit auf $n$ Elementen braucht $\geq \lceil \log n! \rceil$ Vergleiche im worst case.
\end{satz}
aber: nur Vergleichsoperationen gezählt. Wie steht es mit arithmetischen Operationen?\\
Für Eingabe $s_1,\ldots, s_n$ berechne $S = \prod_{i<j}(s_i-s_j)$\\
\texttt{if S = 0 return 'Nein' else return 'Ja'}.\\
Nur 2 Vergleiche! $\to$ Modell unzureichend !
\subsubsection{algebraische Entscheidungsbäume}
Erweitern Entscheidungsbäume um unäre Konten (1 Kind).\\
Diese sind markiert mit Ergebnissen von arithmetischen Operationen ($+,-,\cdot,\div,\sqrt{}$) auf Vorgängerknoten.\\
$\to$ algebraische Entscheidungsbaumalgorithmen\\
Die worst-case Komplexität eines algebraischen Entscheidungsbaumalgorithmus $T$ ist definiert als die Tiefe von $T$ (längster Pfad von Wurzel zu einem Blatt).\\
Die worst-case Komplexität des Mitgliedschafts-Problems von einer Menge $V \in \R^n$ ist definiert als die minimale Tiefe eines algebraischen Entscheidungsbaumes der die charakteristische Funktion von $V$ berechnet.\\
Beispiel: $V :\!= \{(s_1,\ldots,s_n) \in \R^n : \prod_{i < j} \ne 0 \}$ ist die Menge der 'Ja' Instanzen des Elementeindeutigkeitsproblems.\\
Sei $V \subset \R^n$. Dann sei $\#V$ die Zahl der Komponenten von $V$.\\
2 Punkte $x,y \in W$ sind in selber Komposition wenn es Kurve innerhalb $W$ gibt, die $x$ und $y$ verbindet.\\
\begin{satz}
von Ben-Or:\\
Sei $T$ ein algebraischer Entscheidungsbaum, der das Mitgliedschaftsproblem für $V \subset \R^n$ löst.\\
Sei $M :\!= \max(\#V,\#(\R^n v))$ und $h$ die Tiefe von $T$.\\
Dann ist $M \geq 2^h \cdot 3^{h+ n}$, damit $h \geq (\log M - n \log 3)/\log 6$
\end{satz}
Für den Satz von Ben-Or gibt es zwei Anwendungen: Elementeindeutigkeit und die konvexe Hülle.
\subsection{Anwendung: Elementeindeutigkeit}
\begin{satz}
Im algebraischen Entscheidungsmodell ist die worst-case Komplexität des Elementeindeutigkeitsproblems bei $n$ reellen Zahlen $\Omega(n\log n)$
\end{satz}
\begin{proof}
$V :\!= \{(s_1,\ldots,s_n) \in \R^n : \prod_{i < j} \ne 0 \}$ ist die Menge der 'Ja' Instanzen.\\
Aus Behauptung: $\lvert V \rvert \geq n!$ folgt, dass Tiefe des Entscheidungsbaums $\geq \dfrac{\log n! - n \log 3}{\log 6} = \Omega(n \log n)$\\
Noch zu zeigen: Behauptung $\lvert V \rvert \geq n!$\\
Seien $\pi$ und $p$ verschiedene Permutationen von $\{1,\ldots n \}.$\\
Seien $P = \pi(1),\ldots \pi(n)$ und $R = p(1), \ldots p(n)$.\\
Dann sind $P$ und $R$ in Menge $V$.\\
Es gibt Indizes $i$ und $j$ mit $\pi(i) < \pi(j)$ und $p(i) > p(j)$.\\
Jede stetige Kurve in $\R^n$ von $P$ nach $R$ verläugt durch einen Punkt mit gleichen $i-$ und $j-$Koordinaten, der also nicht in $V$ ist.\\
$\Rightarrow P$ und $R$ gehören zu verschiedenen Komponenten von $V$.
\end{proof}